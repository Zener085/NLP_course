{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T11:22:35.272493Z",
     "start_time": "2024-04-08T11:22:35.045611Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = \"data/\"\n",
    "\n",
    "train_df = pd.read_csv(f\"{data_path}train.csv\")\n",
    "train_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id                                        EN  \\\n",
       "0   0           I couldn't understand his joke.   \n",
       "1   1  There was nothing Tom could do about it.   \n",
       "2   2                          He has a hat on.   \n",
       "3   3              Does that happen every time?   \n",
       "4   4        Please don't run in the classroom.   \n",
       "\n",
       "                                           NL  \n",
       "0                  Ik begreep zijn grap niet.  \n",
       "1        Er was niets dat Tom eraan kon doen.  \n",
       "2                        Hij draagt een hoed.  \n",
       "3                      Gebeurt dat elke keer?  \n",
       "4  Alsjeblieft niet rennen in het klaslokaal.  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EN</th>\n",
       "      <th>NL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I couldn't understand his joke.</td>\n",
       "      <td>Ik begreep zijn grap niet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>There was nothing Tom could do about it.</td>\n",
       "      <td>Er was niets dat Tom eraan kon doen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>He has a hat on.</td>\n",
       "      <td>Hij draagt een hoed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Does that happen every time?</td>\n",
       "      <td>Gebeurt dat elke keer?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Please don't run in the classroom.</td>\n",
       "      <td>Alsjeblieft niet rennen in het klaslokaal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:22:35.282692Z",
     "start_time": "2024-04-08T11:22:35.274487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "\n",
    "def unicode2ascii(s):\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = unicode2ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ],
   "id": "6b41e0efb2707fa6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:22:35.305200Z",
     "start_time": "2024-04-08T11:22:35.284684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def preprocess(texts):\n",
    "    for text in tqdm(texts, desc=\"Building vocab\"):\n",
    "        tokens = normalize_string(str(text)).split()\n",
    "        yield tokens"
   ],
   "id": "8b4311009496685e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:22:41.710221Z",
     "start_time": "2024-04-08T11:22:35.306712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "SPECIAL_TOKENS = [\"<SOS>\", \"<EOS>\", \"<UNK>\", \"<PAD>\"]\n",
    "english_vocab = build_vocab_from_iterator(\n",
    "    preprocess(train_df[\"EN\"].values), special_first=True, specials=SPECIAL_TOKENS\n",
    ")\n",
    "\n",
    "dutch_vocab = build_vocab_from_iterator(\n",
    "    preprocess(train_df[\"NL\"].values), special_first=True, specials=SPECIAL_TOKENS\n",
    ")"
   ],
   "id": "a12690073e1c946c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building vocab: 100%|██████████| 68601/68601 [00:01<00:00, 52049.24it/s]\n",
      "Building vocab: 100%|██████████| 68601/68601 [00:01<00:00, 49141.01it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:22:41.723282Z",
     "start_time": "2024-04-08T11:22:41.714211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Length of english vocab:\", len(english_vocab))\n",
    "print(\"Length of dutch vocab:\", len(dutch_vocab))"
   ],
   "id": "81ca95ce16f005be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of english vocab: 9494\n",
      "Length of dutch vocab: 13854\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:22:41.789988Z",
     "start_time": "2024-04-08T11:22:41.726277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SOS_TOKEN_IDX = english_vocab[\"<SOS>\"]\n",
    "EOS_TOKEN_IDX = english_vocab[\"<EOS>\"]\n",
    "MAX_LENGTH = 100\n",
    "\n",
    "\n",
    "def sentence2idxs(vocab, sentence):\n",
    "    tokens = normalize_string(str(sentence)).split(\" \")\n",
    "    return [vocab[word] if word in vocab else vocab[\"<UNK>\"] for word in tokens]\n",
    "\n",
    "\n",
    "def sentence2tensor(vocab, sentence):\n",
    "    indexes = sentence2idxs(vocab, sentence)\n",
    "    indexes.append(EOS_TOKEN_IDX)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "\n",
    "def process_sentence(vocab, sentence):\n",
    "    idxs = sentence2idxs(vocab, sentence)\n",
    "    idxs.append(EOS_TOKEN_IDX)\n",
    "    return idxs\n",
    "\n",
    "\n",
    "def get_dataloader(df, input_vocab, output_vocab, batch_size=64, in_column=\"EN\", out_column=\"NL\"):\n",
    "    n = len(df)\n",
    "    input_idxs = np.ones((n, MAX_LENGTH), dtype=np.int32) * input_vocab[\"<PAD>\"]\n",
    "    target_idxs = np.ones((n, MAX_LENGTH), dtype=np.int32) * output_vocab[\"<PAD>\"]\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=n):\n",
    "        in_lang_idxs = process_sentence(input_vocab, row[in_column])\n",
    "        out_lang_idxs = process_sentence(output_vocab, row[out_column])\n",
    "\n",
    "        input_idxs[idx, : len(in_lang_idxs)] = in_lang_idxs\n",
    "        target_idxs[idx, : len(out_lang_idxs)] = out_lang_idxs\n",
    "\n",
    "    data = TensorDataset(\n",
    "        torch.LongTensor(input_idxs).to(device),\n",
    "        torch.LongTensor(target_idxs).to(device),\n",
    "    )\n",
    "\n",
    "    dataloader = DataLoader(data, batch_size=batch_size)\n",
    "    return dataloader"
   ],
   "id": "5e938cbe8ca9ef25",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:22:41.803118Z",
     "start_time": "2024-04-08T11:22:41.792987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.2):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ],
   "id": "38bccdbfeccfc1e6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:22:41.822240Z",
     "start_time": "2024-04-08T11:22:41.806110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(\n",
    "            batch_size, 1, dtype=torch.long, device=device\n",
    "        ).fill_(SOS_TOKEN_IDX)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden = self.forward_step(\n",
    "                decoder_input, decoder_hidden\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(\n",
    "                    -1\n",
    "                ).detach()\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ],
   "id": "72ffd0016a6cb075",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:22:41.833557Z",
     "start_time": "2024-04-08T11:22:41.825234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch(\n",
    "    dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion\n",
    "):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in tqdm(dataloader):\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)), target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ],
   "id": "6baa04e4431ac065",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:22:41.846588Z",
     "start_time": "2024-04-08T11:22:41.838546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001):\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        loss = train_epoch(\n",
    "            train_dataloader,\n",
    "            encoder,\n",
    "            decoder,\n",
    "            encoder_optimizer,\n",
    "            decoder_optimizer,\n",
    "            criterion,\n",
    "        )\n",
    "        print(\"Epoch:\", epoch, \"loss:\", loss)"
   ],
   "id": "ffc5b30c15787c51",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T11:22:54.101810Z",
     "start_time": "2024-04-08T11:22:41.848584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden_size = 128\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = get_dataloader(train_df, english_vocab, dutch_vocab, batch_size)\n",
    "\n",
    "encoder = EncoderRNN(len(english_vocab), hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, len(dutch_vocab)).to(device)"
   ],
   "id": "bd1a826d29810c90",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68601/68601 [00:11<00:00, 5924.44it/s]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:00:15.606893Z",
     "start_time": "2024-04-08T11:22:54.103785Z"
    }
   },
   "cell_type": "code",
   "source": "train(train_dataloader, encoder, decoder, n_epochs=20)",
   "id": "e36d5a714df34710",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [02:20<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 loss: 0.47423904305740966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [02:05<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 0.3062274100731558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:45<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 loss: 0.2542075140318319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:48<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 loss: 0.22615738603661753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:56<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 loss: 0.20622452106604824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:55<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 loss: 0.19032614177732327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:50<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 loss: 0.17713069580773363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:48<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 loss: 0.1658668840137213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:49<00:00,  9.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 loss: 0.15610195814506778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:48<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 loss: 0.1476164728389191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:46<00:00, 10.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 loss: 0.14015030847000542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:50<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 loss: 0.13355577340238353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:48<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 loss: 0.12755342138541945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:45<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 loss: 0.12217226118516566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:45<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 loss: 0.11723541822145457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:43<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 loss: 0.1128037782288643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:47<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 loss: 0.10872341763339381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:53<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 loss: 0.10494116076560163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:56<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 loss: 0.10142438000401677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [01:52<00:00,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 loss: 0.09823629308019334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:01:01.617379Z",
     "start_time": "2024-04-08T12:01:01.598845Z"
    }
   },
   "cell_type": "code",
   "source": "test_df = pd.read_csv(f\"{data_path}test.csv\")",
   "id": "c22a37894779ac39",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:38:34.418544Z",
     "start_time": "2024-04-08T12:38:34.409699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate_sentence(sentence, encoder, decoder):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = sentence2tensor(english_vocab, sentence)\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        decoded_words = [dutch_vocab.lookup_token(token) for token in decoder_outputs.topk(1)[1][0]]\n",
    "        answer = \" \".join(decoded_words[:decoded_words.index(\"<EOS>\")]) if \"<EOS>\" in decoded_words else \" \".join(decoded_words)\n",
    "        if answer:\n",
    "            return answer\n",
    "        return \"Ik heb het woordenboek.\""
   ],
   "id": "b88d9b7c3c66c0a",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:43:40.298907Z",
     "start_time": "2024-04-08T12:38:34.999967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translations = []\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Translating\"):\n",
    "    translation = translate_sentence(row[\"EN\"], encoder, decoder)\n",
    "    translations.append(translation)\n",
    "\n",
    "submission_df = pd.DataFrame({\"id\": test_df[\"id\"], \"prediction\": translations})\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ],
   "id": "8a67466b844bcdf0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 7623/7623 [05:05<00:00, 24.97it/s]\n"
     ]
    }
   ],
   "execution_count": 53
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
