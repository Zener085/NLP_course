{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-vb8yFOGRDF"
   },
   "source": [
    "## Implement context-sensitive spelling correction\n",
    "\n",
    "Here's a spelling correction model I found [here](https://norvig.com/spell-correct.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MoQeEsZvHvvi",
    "ExecuteTime": {
     "end_time": "2024-03-21T10:19:42.418532Z",
     "start_time": "2024-03-21T10:19:41.742534Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def words(text): return re.findall(r\"\\w+\", text.lower())\n",
    "\n",
    "\n",
    "WORDS = Counter(words(open(\"data/big.txt\").read()))\n",
    "\n",
    "\n",
    "def P(word, n=sum(WORDS.values())):\n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / n\n",
    "\n",
    "\n",
    "def correction(word):\n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "\n",
    "def candidates(word):\n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return known([word]) or known(edits1(word)) or known(edits2(word)) or [word]\n",
    "\n",
    "\n",
    "def known(words):\n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "    inserts = [L + c + R for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "\n",
    "def edits2(word):\n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The problem of this model is that it's not context-sensitive. To do that, I decided to add 2 BigGrams' dictionaries of words:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def create_bigram_dict(text, after: bool = True):\n",
    "    \"\"\"\n",
    "    Creates dictionary of Bigram.\n",
    "    \n",
    "    Parameters:\n",
    "        text: Input text to learn.\n",
    "        after: If there should be dictionary for words after (True) or before (False)\n",
    "    \"\"\"\n",
    "    bigram_dict = defaultdict(lambda: defaultdict(int))\n",
    "    text_words = words(text)\n",
    "    for i in range(len(text_words) - 1):\n",
    "        if after:\n",
    "            bigram_dict[text_words[i]][text_words[i + 1]] += 1\n",
    "        else:\n",
    "            bigram_dict[text_words[i + 1]][text_words[i]] += 1\n",
    "    return bigram_dict\n",
    "\n",
    "\n",
    "BIGRAM_DICT_AFTER = create_bigram_dict(open(\"data/big.txt\").read())\n",
    "BIGRAM_DICT_BEFORE = create_bigram_dict(open(\"data/big.txt\").read(), False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:14:57.441564Z",
     "start_time": "2024-03-21T10:14:55.188373Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "How do they work? Well, the first dictionary calculates number of appearance of each word AFTER another one.\n",
    "Another dictionary makes vice versa, i.e. it stores number of appearance of each word BEFORE another one.\n",
    "By doing that, we can calculate probability of appearance of some corrected word in the sentence."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def p_bi(word1: str = \"\", word2: str = \"\", word3: str = \"\", n=sum(WORDS.values())):\n",
    "    \"\"\"\n",
    "    Probability of `word2` given `word1` before or after.\n",
    "    \n",
    "    Parameters:\n",
    "        word1: The word before.\n",
    "        word2: The actual word.\n",
    "        word3: The word after.\n",
    "        n: Number of words counted.\n",
    "    \"\"\"\n",
    "    assert word2 != \"\", \"The word to be corrected cannot be empty!\"\n",
    "\n",
    "    after = BIGRAM_DICT_AFTER[word1][word2] if word1 != \"\" else 0\n",
    "    before = BIGRAM_DICT_BEFORE[word2][word3] if word3 != \"\" else 0\n",
    "    return (after + before) / n\n",
    "\n",
    "\n",
    "def correction_bi(prev_word: str = \"\", act_word: str = \"\", next_word: str = \"\"):\n",
    "    \"\"\"\n",
    "    Most probable spelling correction for word given the previous word.\n",
    "    \n",
    "    Parameters:\n",
    "        prev_word: The word before.\n",
    "        act_word: The actual word.\n",
    "        next_word: The word after.\n",
    "    \"\"\"\n",
    "    return max(candidates(act_word), key=lambda word: p_bi(prev_word, word, next_word))\n",
    "\n",
    "\n",
    "def correct_sentence_bi(sentence):\n",
    "    \"\"\"\n",
    "    Corrects all words in the sentence.\n",
    "    \"\"\"\n",
    "    text_words = words(sentence)\n",
    "    corrected_words = [text_words[0]]\n",
    "\n",
    "    for i in range(1, len(text_words)):\n",
    "        corrected_words.append(correction_bi(corrected_words[i - 1], text_words[i]))\n",
    "\n",
    "    return \" \".join(corrected_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:19:13.409685Z",
     "start_time": "2024-03-21T10:19:13.402502Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'i had seen little of holmes lately'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentence_bi(\"I hadd seen littl of Holmess lately\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:19:49.605168Z",
     "start_time": "2024-03-21T10:19:49.599167Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another problem can be is that the word before can be more in inluential than word after the corrected one or vice versa. Let's add nice coefficients for that:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def p_bi_coeffs(word1: str = \"\", word2: str = \"\", word3: str = \"\", n: int = sum(WORDS.values()), coeff_after: float = 1.0, coeff_before: float = 1.0):\n",
    "    \"\"\"\n",
    "    Probability of `word2` given `word1` before or after.\n",
    "    \n",
    "    Parameters:\n",
    "        word1: The word before.\n",
    "        word2: The actual word.\n",
    "        word3: The word after.\n",
    "        n: Number of words counted.\n",
    "        coeff_after: Coefficient of the probability to be after another one.\n",
    "        coeff_before: Coefficient of the probability to be before another one.\n",
    "    \"\"\"\n",
    "    assert word2 != \"\", \"The word to be corrected cannot be empty!\"\n",
    "\n",
    "    after = BIGRAM_DICT_AFTER[word1][word2] if word1 != \"\" else 0\n",
    "    before = BIGRAM_DICT_BEFORE[word2][word3] if word3 != \"\" else 0\n",
    "\n",
    "    return (after * coeff_after + before * coeff_before) / n\n",
    "\n",
    "\n",
    "def correction_bi_coeffs(prev_word: str = \"\", act_word: str = \"\", next_word: str = \"\", coeff_after: float = 1.0, coeff_before: float = 1.0):\n",
    "    \"\"\"\n",
    "    Most probable spelling correction for word given the previous word.\n",
    "    \n",
    "    Parameters:\n",
    "        prev_word: The first word.\n",
    "        act_word: The second word.\n",
    "        next_word: The third word.\n",
    "        coeff_after: Coefficient of the probability to be after another one.\n",
    "        coeff_before: Coefficient of the probability to be before another one.\n",
    "    \"\"\"\n",
    "    return max(candidates(act_word), key=lambda word: p_bi_coeffs(prev_word, word, next_word, coeff_after=coeff_after, coeff_before=coeff_before))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:24:33.303811Z",
     "start_time": "2024-03-21T10:24:33.293990Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  coeff1   |  coeff2   |\n",
      "-------------------------------------------------\n",
      "| \u001B[0m1        \u001B[0m | \u001B[0m0.8798   \u001B[0m | \u001B[0m0.417    \u001B[0m | \u001B[0m0.7203   \u001B[0m |\n",
      "| \u001B[0m2        \u001B[0m | \u001B[0m0.8478   \u001B[0m | \u001B[0m0.0001144\u001B[0m | \u001B[0m0.3023   \u001B[0m |\n",
      "| \u001B[95m3        \u001B[0m | \u001B[95m0.8889   \u001B[0m | \u001B[95m0.1468   \u001B[0m | \u001B[95m0.09234  \u001B[0m |\n",
      "| \u001B[0m4        \u001B[0m | \u001B[0m0.8795   \u001B[0m | \u001B[0m0.1863   \u001B[0m | \u001B[0m0.3456   \u001B[0m |\n",
      "| \u001B[0m5        \u001B[0m | \u001B[0m0.8815   \u001B[0m | \u001B[0m0.3968   \u001B[0m | \u001B[0m0.5388   \u001B[0m |\n",
      "| \u001B[95m6        \u001B[0m | \u001B[95m0.89     \u001B[0m | \u001B[95m0.1575   \u001B[0m | \u001B[95m0.08241  \u001B[0m |\n",
      "| \u001B[95m7        \u001B[0m | \u001B[95m0.8913   \u001B[0m | \u001B[95m0.3302   \u001B[0m | \u001B[95m0.1536   \u001B[0m |\n",
      "| \u001B[0m8        \u001B[0m | \u001B[0m0.8725   \u001B[0m | \u001B[0m0.1493   \u001B[0m | \u001B[0m0.6288   \u001B[0m |\n",
      "| \u001B[95m9        \u001B[0m | \u001B[95m0.9065   \u001B[0m | \u001B[95m0.489    \u001B[0m | \u001B[95m0.0      \u001B[0m |\n",
      "| \u001B[95m10       \u001B[0m | \u001B[95m0.907    \u001B[0m | \u001B[95m0.6802   \u001B[0m | \u001B[95m0.0      \u001B[0m |\n",
      "| \u001B[0m11       \u001B[0m | \u001B[0m0.894    \u001B[0m | \u001B[0m0.7451   \u001B[0m | \u001B[0m0.2403   \u001B[0m |\n",
      "| \u001B[0m12       \u001B[0m | \u001B[0m0.9061   \u001B[0m | \u001B[0m0.9905   \u001B[0m | \u001B[0m0.007976 \u001B[0m |\n",
      "| \u001B[0m13       \u001B[0m | \u001B[0m0.8843   \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m1.0      \u001B[0m |\n",
      "| \u001B[0m14       \u001B[0m | \u001B[0m0.8948   \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m0.2508   \u001B[0m |\n",
      "| \u001B[0m15       \u001B[0m | \u001B[0m0.8758   \u001B[0m | \u001B[0m0.1484   \u001B[0m | \u001B[0m0.4067   \u001B[0m |\n",
      "| \u001B[0m16       \u001B[0m | \u001B[0m0.9069   \u001B[0m | \u001B[0m0.8285   \u001B[0m | \u001B[0m0.0005093\u001B[0m |\n",
      "| \u001B[0m17       \u001B[0m | \u001B[0m0.9065   \u001B[0m | \u001B[0m0.8269   \u001B[0m | \u001B[0m0.00294  \u001B[0m |\n",
      "| \u001B[0m18       \u001B[0m | \u001B[0m0.8893   \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m0.5847   \u001B[0m |\n",
      "| \u001B[0m19       \u001B[0m | \u001B[0m0.8534   \u001B[0m | \u001B[0m0.009502 \u001B[0m | \u001B[0m0.9969   \u001B[0m |\n",
      "| \u001B[0m20       \u001B[0m | \u001B[0m0.8806   \u001B[0m | \u001B[0m0.6516   \u001B[0m | \u001B[0m1.0      \u001B[0m |\n",
      "| \u001B[0m21       \u001B[0m | \u001B[0m0.8878   \u001B[0m | \u001B[0m0.733    \u001B[0m | \u001B[0m0.5304   \u001B[0m |\n",
      "| \u001B[0m22       \u001B[0m | \u001B[0m0.8957   \u001B[0m | \u001B[0m0.5579   \u001B[0m | \u001B[0m0.1276   \u001B[0m |\n",
      "| \u001B[0m23       \u001B[0m | \u001B[0m0.9068   \u001B[0m | \u001B[0m0.5737   \u001B[0m | \u001B[0m0.001391 \u001B[0m |\n",
      "| \u001B[0m24       \u001B[0m | \u001B[0m0.8737   \u001B[0m | \u001B[0m0.2195   \u001B[0m | \u001B[0m0.8328   \u001B[0m |\n",
      "| \u001B[0m25       \u001B[0m | \u001B[0m0.9066   \u001B[0m | \u001B[0m0.9166   \u001B[0m | \u001B[0m0.001539 \u001B[0m |\n",
      "=================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.6802245829897484, 0.0)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from random import choice\n",
    "\n",
    "\n",
    "def test_acc(coeff1: float = 1.0, coeff2: float = 1.0):\n",
    "    corrected_words = 0\n",
    "    total_words = 0\n",
    "\n",
    "    with open(\"data/big.txt\") as f:\n",
    "        for line in f:\n",
    "            text_words = words(line)\n",
    "            for i in range(1, len(text_words) - 1):\n",
    "                uncorrect = text_words[i] + choice(\"qwertyuiopasdfghjklzxcvbnm\")\n",
    "                corrected_word = correction_bi_coeffs(text_words[i - 1], uncorrect, text_words[i + 1], coeff1, coeff2)\n",
    "                if corrected_word == text_words[i]:\n",
    "                    corrected_words += 1\n",
    "                total_words += 1\n",
    "\n",
    "    return corrected_words / total_words\n",
    "\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=test_acc,\n",
    "    pbounds={\"coeff1\": (0, 1), \"coeff2\": (0, 1)},\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=5, n_iter=20)\n",
    "optimizer.max[\"params\"][\"coeff1\"], optimizer.max[\"params\"][\"coeff2\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T13:08:47.607341Z",
     "start_time": "2024-03-21T12:03:17.538352Z"
    }
   },
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, the word after does no make ane influence on the corrected word."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46rk65S4GRSe"
   },
   "source": [
    "## Evaluate on a test set\n",
    "Here's an evaluation of the final model I created.\n",
    "To test the model, I add random letter to the end of each word from the test text.\n",
    "We count number of right corrections of that and measure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OwZWaX9VVs7B",
    "ExecuteTime": {
     "end_time": "2024-03-21T10:20:51.470616Z",
     "start_time": "2024-03-21T10:20:51.467383Z"
    }
   },
   "outputs": [],
   "source": [
    "test_acc(optimizer.max[\"params\"][\"coeff1\"], optimizer.max[\"params\"][\"coeff2\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
